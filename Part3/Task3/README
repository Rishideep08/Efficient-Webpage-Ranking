In this part of the assignment we used caching to store the data in the memory to reduce the disk operations and optimizing the page rank algorithm code.

To run this algortithm use the following command and run this command from the code file path folder.

{Path to SPark-submit} {code file path} {hdfs file path for input} {hdf file path for output}
example /mnt/data/spark-3.3.0-bin-hadoop3/sbin/spark-submit Ass1_P3task1.py hdfs:10.10.1.1:9000/SortDataInput.csv hdfs:10.10.1.1:9000/SortDataOutput.csv 

or else we can use run.sh script as follows

bash {pathTorun.sh} {Path to Spark-submit} {code file path} {hdfs file path for input} {hdf file path for output}

Example:
 bash ass1-code/Part3/Task3/run.sh /mnt/data/spark-3.3.0-bin-hadoop3/bin/spark-submit ass1-code/Part3/Task3/Ass1_P3task3.py hdfs://10.10.1.1:9000/PageRankData/enwiki-pages-articles/\* hdfs://10.10.1.1:9000/PageRankData/OptiResultsTask4

Note1: 
 if the output folder already exists in hadoop hdfs please delete it before every run.

Note2: Add the below Spark Configuration on spark-defaults.conf file
spark.driver.memory 30g
spark.executor.memory 30g
spark.executor.cores 5
spark.task.cpus 1
spark.local.dir /mnt/data/
spark.speculation true
spark.master spark://10.10.1.1:7077